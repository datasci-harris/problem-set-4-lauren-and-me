---
title: "Your Title"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points. 
We use (`*`) to indicate a problem that we think might be time consuming. 
    
## Style Points (10 pts) 
Please refer to the minilesson on code style
**[here](https://uchicago.zoom.us/rec/share/pG_wQ-pHTQrJTmqNn4rcrw5V194M2H2s-2jdy8oVhWHkd_yZt9o162IWurpA-fxU.BIQlSgZLRYctvzp-)**.

## Submission Steps (10 pts)
1. This problem set is a paired problem set.
2. Play paper, scissors, rock to determine who goes first. Call that person *Partner 1*.
    - Partner 1 Lauren Laine, llaine:
    - Partner 2 (name and cnet ID):
3. Partner 1 will accept the `ps4` and then share the link it creates with their partner. You can only share it with one partner so you will not be able to change it after your partner has accepted. 
4. "This submission is our work alone and complies with the 30538 integrity policy." Add your initials to indicate your agreement: \*\*\_\_\*\* \*\*\_\_\*\*
5. "I have uploaded the names of anyone else other than my partner and I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  (1 point)
6. Late coins used this pset: \*\*\_\_\*\* Late coins left after submission: \*\*\_\_\*\*
7. Knit your `ps4.qmd` to an PDF file to make `ps4.pdf`, 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
8. (Partner 1): push  `ps4.qmd` and `ps4.pdf` to your github repo.
9. (Partner 1): submit `ps4.pdf` via Gradescope. Add your partner on Gradescope.
10. (Partner 1): tag your submission in Gradescope

**Important:** Repositories are for tracking code. **Do not commit the data or shapefiles to your repo.** The best way to do this is with `.gitignore`, which we have covered in class. If you do accidentally commit the data, Github has a [guide](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github#removing-files-from-a-repositorys-history). The best course of action depends on whether you have pushed yet. This also means that both partners will have to download the initial raw data and any data cleaning code will need to be re-run on both partners' computers. 





## Download and explore the Provider of Services (POS) file (10 pts)

1. 
2. 
    a.
    b.

```{python}
#import libraries
import pandas as pd
import altair as alt
import shapely
from shapely import Polygon, Point
```
**Question 1.2**
```{python}
pos2016=pd.read_csv(r"C:\Users\laine\OneDrive\Documents\GitHub\problem-set-4-lauren-and-me\pos2016.csv")
```

```{python}
short_term_hos_2016=pos2016[pos2016['PRVDR_CTGRY_CD']==1]
short_term_hos_2016=short_term_hos_2016[short_term_hos_2016['PRVDR_CTGRY_SBTYP_CD']==1]
short_term_hos_2016['year']=2016
print(len(short_term_hos_2016))
```
There are 7245 hospitals reported in this data. This seems very low. The Kaiser Family Foundation article reports that "here are nearly 5,000 short-term, acute care hospitals in the United States". That estimate may be smaller because they are filtering down even further to acute care hospitals. 

Definitive Healthcare reports 3,873 short term acute care hospitals as of April 2024. That estimate is much lower than the estimate from the 2016 data. There may have been many hospital closures since 2016 but it seems unlikely that the number of short term hospitals would decrease by almost 50%. 

Kaiser Family Foundation article: https://www.kff.org/report-section/a-look-at-rural-hospital-closures-and-implications-for-access-to-care-three-case-studies-issue-brief/ 

Definitive Healthcare article: https://www.definitivehc.com/blog/how-many-hospitals-are-in-the-us 
3. 
**Question 1.3**

```{python}
# import and subset pos2017
pos2017=pd.read_csv(r"C:\Users\laine\OneDrive\Documents\GitHub\problem-set-4-lauren-and-me\pos2017.csv")
short_term_hos_2017=pos2017[pos2017['PRVDR_CTGRY_CD']==1]
short_term_hos_2017=short_term_hos_2017[short_term_hos_2017['PRVDR_CTGRY_SBTYP_CD']==1]
short_term_hos_2017['year']=2017
print(len(short_term_hos_2017))
```

```{python}
# import and subset pos2018
pos2018=pd.read_csv(r"C:\Users\laine\OneDrive\Documents\GitHub\problem-set-4-lauren-and-me\pos2018.csv")
short_term_hos_2018=pos2018[pos2018['PRVDR_CTGRY_CD']==1]
short_term_hos_2018=short_term_hos_2018[short_term_hos_2018['PRVDR_CTGRY_SBTYP_CD']==1]
short_term_hos_2018['year']=2018
print(len(short_term_hos_2018))
```

```{python}
# import and subset pos2018
pos2019=pd.read_csv(r"C:\Users\laine\OneDrive\Documents\GitHub\problem-set-4-lauren-and-me\pos2019.csv")
short_term_hos_2019=pos2019[pos2019['PRVDR_CTGRY_CD']==1]
short_term_hos_2019=short_term_hos_2019[short_term_hos_2019['PRVDR_CTGRY_SBTYP_CD']==1]
short_term_hos_2019['year']=2019
print(len(short_term_hos_2019))
```

There are 7260 short term hospitals in the 2017 dataset. There are 7277 short term hospitals in the 2018 dataset. There are 7303 short term hospitals in the 2019 dataset. 


```{python}
full_df=pd.concat([short_term_hos_2016,short_term_hos_2017,short_term_hos_2018,short_term_hos_2019])
```

```{python}
alt.data_transformers.disable_max_rows()
plot_1_3=alt.Chart(full_df, title="Number of Short Term Hospitals by Year").mark_bar().encode(
    alt.X('year:Q'),
    alt.Y('count(FAC_NAME):Q')
)
plot_1_3
```
4. 
    a.
    b.
**Question 1.4**

```{python}
#learned about the drop_duplicates function 
#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html
unique_nums2016=short_term_hos_2016.drop_duplicates(subset='PRVDR_NUM', keep='first')
# check if duplicates were dropped
unique_nums2016.groupby('PRVDR_NUM').size().head(15)
unique_nums2017=full_df[full_df['year']==2017].drop_duplicates(subset='PRVDR_NUM', keep='first')
unique_nums2018=full_df[full_df['year']==2018].drop_duplicates(subset='PRVDR_NUM', keep='first')
unique_nums2019=full_df[full_df['year']==2019].drop_duplicates(subset='PRVDR_NUM', keep='first')
full_unique_nums=pd.concat([unique_nums2016, unique_nums2017, unique_nums2018, unique_nums2019])
```

```{python}
unique_hos_plot=alt.Chart(full_unique_nums).mark_bar().encode(
    alt.X('year').title("Year"),
    alt.Y('count(FAC_NAME):Q').title("Number of Observations")
)
unique_hos_plot
```
The unique provider number plot looks almost identical to the plot before filtering out duplicates. This suggests that almost all of the hospitals already had a unique provider number. 

## Identify hospital closures in POS file (15 pts) (*)

1. 
2. 
3. 
    a.
    b.
    c.

## Download Census zip code shapefile (10 pt) 

1. 
    a. 
    The file types are .dbf, .prj, .shp, .shx, and .xml.
    The .dbf file has attribute information 
    The .prj file describes the Coordinate Reference System.
    The .shp has feature geometrics.
    The .shx has a positional index. 
    The .xml file has details on where the data was obtained, and how often it is updated, and other notes on data use. 


    b. 
    The .dbf file is 6,275 KB
    The .prj file is 1 KB
    The .shp file is 817,915 KB
    The .shx file is 259 KB
    The .xml file is 16 KB

2. 

```{python}
import geopandas as gpd
census_data=gpd.read_file(r"C:\Users\laine\OneDrive\Documents\GitHub\problem-set-4-lauren-and-me\gz_2010_us_860_00_500k.shp")
```

```{python}
census_data.head()
# used ChatGPT to Debug and filter to multipel prefixes. 
#prompt "How can I filter to multiple startswith strings"
prefixes=('75', '76', '77', '78', '79')
census_data['texas']=census_data['ZCTA5'].map(lambda x: 1 if any(str(x).startswith(prefix) for prefix in prefixes)else 0)
texas_data=census_data[census_data['texas']==1]

```

## Calculate zip codeâ€™s distance to the nearest hospital (20 pts) (*)

1. 
2. 
3. 
4. 
    a.
    b.
5. 
    a.
    b.
    c.
    
## Effects of closures on access in Texas (15 pts)

1. 
2. 
3. 
4. 

## Reflecting on the exercise (10 pts) 
